{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f5be41",
   "metadata": {},
   "source": [
    "There are three types of words this document tries to remove on a copy of the dataframe (each type is in its own list):\n",
    "1. Company names.\n",
    "2. Adjectives.\n",
    "3. Miscellaneous.\n",
    "\n",
    "I made a search function to help me collect a lot of the words in the lists. This search function is located at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403465f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5065a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bf8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WhatsCooking is the folder my data is in\n",
    "\n",
    "food = pd.read_json('../WhatsCooking/TrainingData/train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928ed81",
   "metadata": {},
   "source": [
    "Before removing anything, it will help to make all words lowercase and use a copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edccfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting a copy of the dataframe\n",
    "\n",
    "copy = food.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fb80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This makes all of the ingredients lowercase\n",
    "\n",
    "for i in range(len(copy['ingredients'])):\n",
    "    for j in range(len(copy['ingredients'][i])):\n",
    "        copy['ingredients'][i][j] = copy['ingredients'][i][j].replace(copy['ingredients'][i][j], copy['ingredients'][i][j].casefold()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c5daa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: .copy is not working as expected so, if you want to check results at the end, run this now\n",
    "\n",
    "## Getting a list of all ingredients in all recipes from original dataframe\n",
    "total_ingredients = []\n",
    "\n",
    "for i in range(len(food['ingredients'])):\n",
    "    total_ingredients.extend(food['ingredients'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bce5a7",
   "metadata": {},
   "source": [
    "# Function for removing characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33537a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic function that removes all words in my_list from copy['ingredients']\n",
    "\n",
    "def remove(my_list):\n",
    "    for i in range(len(copy['ingredients'])):\n",
    "        for word in my_list:\n",
    "            for j in range(len(copy['ingredients'][i])):\n",
    "                copy['ingredients'][i][j] = copy['ingredients'][i][j].replace(word, '').strip()\n",
    "                \n",
    "## Warning: this function can be very slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ac611",
   "metadata": {},
   "source": [
    "# 1. Removing Company Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502bb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is my current list of company names\n",
    "    ## it is probably incomplete\n",
    "    ## it is mostly alphabetical\n",
    "\n",
    "companies = ['™',\n",
    " '®',\n",
    " 'a taste of thai',\n",
    " 'accent',\n",
    " 'adobo',\n",
    " 'alaskan',\n",
    " 'alexia',\n",
    " 'argo',\n",
    " 'azteca',\n",
    " 'baileys',\n",
    " 'barilla',\n",
    " 'barilla oven-ready',\n",
    " 'bertolli',\n",
    " \"hellmann' or\",\n",
    " 'best foods real',\n",
    " 'best food real',\n",
    " \"best food's\",\n",
    " 'best food light',\n",
    " 'best food canola cholesterol free',\n",
    " 'better than bouillon',\n",
    " 'betty crocker',\n",
    " 'bisquick',\n",
    " 'bob evans',\n",
    " 'bragg',\n",
    " \"breakstone's\",\n",
    " 'breyers',\n",
    " 'camellia',\n",
    " \"campbell's\",\n",
    " 'cholula',\n",
    " 'classico',\n",
    " \"colman's\",\n",
    " 'crisco',\n",
    " 'crescent recipe creations',\n",
    " 'crystal farms',\n",
    " 'crystal',\n",
    " 'curry guy',\n",
    " 'daisy',\n",
    " 'delallo',\n",
    " 'diamond',\n",
    " 'diamond crystal',\n",
    " 'dole',\n",
    " 'domino',\n",
    " 'earth balance',\n",
    " \"eggland's best\",\n",
    " 'elmlea',\n",
    " 'equal',\n",
    " 'estancia',\n",
    " 'everglades',\n",
    " 'fisher',\n",
    " 'flora',\n",
    " 'foster farms',\n",
    " \"frank's redhot\",\n",
    " 'gebhardt',\n",
    " 'godiva',\n",
    " 'gold medal',\n",
    " 'good seasons',\n",
    " 'gourmet garden',\n",
    " 'goya',\n",
    " 'green giant',\n",
    " 'haas',\n",
    " 'hatch green',\n",
    " 'heath',\n",
    " \"hellmann's\",\n",
    " \"hellmann''s\",\n",
    " 'hellmannâ€ or best food canola',\n",
    " 'heinz',\n",
    " 'herdez',\n",
    " 'hidden valley farmhouse originals',\n",
    " 'hidden valley original',\n",
    " 'hidden valley greek yogurt original',\n",
    " 'hogue',\n",
    " 'holland house',\n",
    " 'hurst family harvest',\n",
    " 'imperial sugar',\n",
    " 'jameson',\n",
    " 'jell-o',\n",
    " 'jif',\n",
    " 'jiffy corn',\n",
    " 'jimmy dean all natural regular',\n",
    " 'jimmy dean',\n",
    " 'johnsonville',\n",
    " 'jose cuervo gold',\n",
    " 'karo',\n",
    " 'kerrygold',\n",
    " 'kikkoman',\n",
    " 'kim crawford',\n",
    " 'klondike',\n",
    " 'knorr',\n",
    " 'knudsen',\n",
    " 'kraft',\n",
    " 'kroger',\n",
    " 'la victoria',\n",
    " 'land o lakes',\n",
    " 'lea & perrins',\n",
    " 'lipton',\n",
    " 'mae ploy',\n",
    " 'madras',\n",
    " 'makers',\n",
    " 'manischewitz',\n",
    " 'martha white',\n",
    " 'mazola',\n",
    " 'mezzetta',\n",
    " 'mccormick',\n",
    " 'minute',\n",
    " 'mission',\n",
    " 'mizkan',\n",
    " 'morton',\n",
    " 'nakano',\n",
    " 'nestle',\n",
    " 'nido',\n",
    " 'nielsen-massey',\n",
    " 'old bay',\n",
    " 'old el paso',\n",
    " 'oreo',\n",
    " 'ortega',\n",
    " 'oscar mayer',\n",
    " 'pam',\n",
    " 'pace',\n",
    " 'pepperidge farm',\n",
    " 'philadelphia',\n",
    " 'pillsbury',\n",
    " 'pompeian',\n",
    " 'prego',\n",
    " 'progresso',\n",
    " 'ragu robusto!',\n",
    " 'ragu',\n",
    " 'red gold',\n",
    " 'ritz',\n",
    " 'ro-tel',\n",
    " 'robert mondavi',\n",
    " 'royal',\n",
    " 'saffron road',\n",
    " 'sargento artisan blends',\n",
    " 'sargento traditional cut',\n",
    " 'skippy',\n",
    " 'smart balance',\n",
    " 'smithfield',\n",
    " 'soy vay',\n",
    " 'spice islands',\n",
    " 'splenda',\n",
    " 'spring!',\n",
    " 'stonefire',\n",
    " 'success',\n",
    " 'swanson',\n",
    " 'swerve',\n",
    " 'syd',\n",
    " 'tabasco',\n",
    " 'taco bell',\n",
    " 'taco bell home originals',\n",
    " 'tapatio',\n",
    " 'texas pete',\n",
    " 'truvía',\n",
    " 'tuttorosso',\n",
    " 'tyson',\n",
    " \"uncle ben's\",\n",
    " 'wesson',\n",
    " 'white lily',\n",
    " 'wholesome sweeteners',\n",
    " 'wish-bone',\n",
    " 'wish-bone robusto',\n",
    " 'wish-bone light',\n",
    " 'wish bone',\n",
    " 'wish-bone',\n",
    " 'wolf brand',\n",
    " 'yoplait greek 100 blackberry pie',\n",
    " 'yoplait greek caramel',\n",
    " 'zatarain’s',\n",
    " 'zatarains']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e08a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will remove all words from the above list from the copied dataframe using the remove function defined above\n",
    "\n",
    "remove(companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8cc512",
   "metadata": {},
   "source": [
    "# 2. Removing Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aeb2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is my current list of adjectives\n",
    "    ## I know it is not complete\n",
    "\n",
    "adj = ['shredded',\n",
    "       'crushed',\n",
    "       'sliced',\n",
    "       'chopped',\n",
    "       'minced',\n",
    "       'crumbled',\n",
    "       'diced',\n",
    "       'halved',\n",
    "       'grated',\n",
    "       'melted',\n",
    "       'drained',\n",
    "       'stone-ground',\n",
    "       'stone ground',\n",
    "       'ground ',\n",
    "       'coarse',\n",
    "       'coars',\n",
    "       'coarse-grain',\n",
    "       'softened',\n",
    "       'refrigerated',\n",
    "       'pre-baked',\n",
    "       'rendered',\n",
    "       'small',\n",
    "       'medium',\n",
    "       'large',\n",
    "       'light',\n",
    "       'lite',\n",
    "       'cholesterol free',\n",
    "       'peeled',\n",
    "       'creamy',\n",
    "       'skinless',\n",
    "       'boneless',\n",
    "       'halves',\n",
    "       'crushed',\n",
    "       'beaten',\n",
    "       'thick-cut',\n",
    "       'pitted',\n",
    "       'oven-ready'\n",
    "       'crumbles',\n",
    "       'whole kernel',\n",
    "       'slim cut',\n",
    "       'classic',\n",
    "       'natural',\n",
    "       'all natural',\n",
    "       'natural',\n",
    "       'free-range',\n",
    "       'heirloom',\n",
    "       'organic',\n",
    "       'traditional',\n",
    "       'kosher',\n",
    "       'raw',\n",
    "       'pure ',\n",
    "       'gluten-free',\n",
    "       'gluten free',\n",
    "       'wheat free',\n",
    "       'homemade',\n",
    "       'store bought',\n",
    "       'vegan',\n",
    "       'vegetarian',\n",
    "       'freeze-dried',\n",
    "       'dried',\n",
    "       'dijonnaise creamy',\n",
    "       'cut up',\n",
    "       'uncooked',\n",
    "       'cooked',\n",
    "       'precooked',\n",
    "       'fully',\n",
    "       'frozen',\n",
    "       'brewed',\n",
    "       'quickcooking',\n",
    "       'quick-cooking',\n",
    "       'baked',\n",
    "       'unbaked',\n",
    "       'prebaked',\n",
    "       'freshly',\n",
    "       'reduced',\n",
    "       'all beef',\n",
    "       'unsalted',\n",
    "       'roasted unsalted',\n",
    "       'dry roasted',\n",
    "       'roasted salted',\n",
    "       'chunky',\n",
    "       'jumbo',\n",
    "       'deveined',\n",
    "       'shell-on',\n",
    "       'uncook',\n",
    "       ' tails',\n",
    "       ' heads',\n",
    "       ' head',\n",
    "       'head on',\n",
    "       'shelled',\n",
    "       'uncook',\n",
    "       'semi-soft',\n",
    "       'soft-shelled',\n",
    "       # sodium reduction\n",
    "       'reduced sodium',\n",
    "       'low sodium',\n",
    "       'less sodium',\n",
    "       'lower sodium',\n",
    "       'low-sodium',\n",
    "       'lowsodium',\n",
    "       'sodium reduced',\n",
    "       'sodium free',\n",
    "       'reduc sodium', # typo is in data\n",
    "       'reduced-sodium',\n",
    "       'no-salt-added',\n",
    "       # fat related\n",
    "       'fat free',\n",
    "       'fat-free',\n",
    "       'fatfree',\n",
    "       'fatfre',\n",
    "       'low-fat',\n",
    "       'low fat',\n",
    "       'Low Fat',\n",
    "       'lowfat',\n",
    "       'reduced fat',\n",
    "       'reduced-fat',\n",
    "       'Reduced Fat',\n",
    "       'non-fat',\n",
    "       'nonfat',\n",
    "       'non fat',\n",
    "       'fat skimmed',\n",
    "       'full fat',\n",
    "       'full-fat',\n",
    "       'fat-trimmed',\n",
    "       'milkfat',\n",
    "       'extra lean',\n",
    "       'extra-lean',\n",
    "       'lean',\n",
    "       # percentages\n",
    "       '1%',\n",
    "       '2%',\n",
    "       '40%',\n",
    "       '95%',\n",
    "       '25%',\n",
    "       '33%',\n",
    "       '96%',\n",
    "       # Specialty products\n",
    "       'amarena',\n",
    "       'amaretti',\n",
    "       'anaheim',\n",
    "       'belgian',\n",
    "       'california',\n",
    "       'castelvetrano',\n",
    "       'dutch-processed',\n",
    "       'dutch processed',\n",
    "       'dungeness',\n",
    "       'fuyu',\n",
    "       'ibarra',\n",
    "       'louisiana',\n",
    "       'manzanilla',\n",
    "       'marcona',\n",
    "       'melba',\n",
    "       'meyer',\n",
    "       'niçoise',\n",
    "       'saigon',\n",
    "       'san Marzano',\n",
    "       'sicilian',\n",
    "       'taiwanese',\n",
    "       'texas',\n",
    "       'toulouse',\n",
    "       'turkish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2716347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will remove all words from the above list from the copied dataframe using the remove function defined above\n",
    "\n",
    "remove(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cebfb",
   "metadata": {},
   "source": [
    "# 3. Removing Random Additional Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c86702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a list of some of the random things seen in the ingredients\n",
    "\n",
    "rdm = [', peel and devein',\n",
    "       ', rins and pat dry',\n",
    "       ', thawed and squeezed dry',\n",
    "       ', cook and drain',\n",
    "       ', thaw and drain',\n",
    "       ', split and toasted',\n",
    "       ', undrain and chop',\n",
    "       ', drained and chopped',\n",
    "       ', thawed and undiluted',\n",
    "       ', rins and drain',\n",
    "       ', drain and flake',\n",
    "       ', soften',\n",
    "       ', drain',\n",
    "       ', slice',\n",
    "       ', sliced',\n",
    "       ', cooked and',\n",
    "       ', fine chop',\n",
    "       ', crush',\n",
    "       ', cooked and',\n",
    "       ',  and',\n",
    "       ', cut into italian loaf',\n",
    "       ', well scrubbed',\n",
    "       ', well scrub',\n",
    "       ', thaw',\n",
    "       ', undrain',\n",
    "       ', cut into',\n",
    "       ', cut french into loaf',\n",
    "       ', crush',\n",
    "       ', crisp-cooked and',\n",
    "       ', 1 inch thick',\n",
    "       ', cut into serving pieces',\n",
    "       'brew family size tea bags',\n",
    "       'skin on',\n",
    "       'skinned',\n",
    "       'bone in',\n",
    "       'bone-in',\n",
    "       'boned',\n",
    "       'in  syrup',\n",
    "       'in the',\n",
    "       'regular or convert',\n",
    "       'in oil',\n",
    "       'packed in olive oil',\n",
    "       'in olive oil',\n",
    "       'in juice',\n",
    "       'in  juice',\n",
    "       'packed in water',\n",
    "       'in water',\n",
    "       'in heavy syrup',\n",
    "       'in light syrup',\n",
    "       'in syrup',\n",
    "       'in natural juice',\n",
    "       '(    oz.)',\n",
    "       '(10 oz.)',\n",
    "       '(15 oz.)',\n",
    "       '(14.5 oz.)',\n",
    "       '(14 oz.)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c216912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will remove all words from the above list from the copied dataframe using the remove function defined above\n",
    "\n",
    "remove(rdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1da0a3",
   "metadata": {},
   "source": [
    "# Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ba6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first entry is the desired list that will be searched\n",
    "    ## duplication of words in list is allowed\n",
    "## second entry is the letters/characters that will be searched for \n",
    "    ## Must be entered in form 'letter'\n",
    "        ## for example, to search for the word onion, use 'onion'\n",
    "## third entry is either the word True or the word False\n",
    "    ## True produces a list\n",
    "    ## False prints the length and prints the list\n",
    "    \n",
    "## Remark: to use the search function, get a list of all of the ingredients first - do not run from a dataframe\n",
    "\n",
    "def search(the_list,word,is_list):\n",
    "    mylist = []\n",
    "    myword = word\n",
    "    \n",
    "    for element in the_list:\n",
    "        if myword in element:\n",
    "            mylist.append(element)\n",
    "    \n",
    "    series_version = pd.Series(mylist)\n",
    "    \n",
    "    if is_list == True:\n",
    "        return(mylist)\n",
    "    \n",
    "    if is_list == False:\n",
    "        print(\"Lenth of list is\", len(series_version.value_counts().index))\n",
    "        print()\n",
    "        print(\"Elements from the list containing the characters:\")\n",
    "        print(series_version.value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51447844",
   "metadata": {},
   "source": [
    "Getting a searchable list of ingredients after removals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae22bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of ingredients after removals of certain words\n",
    "\n",
    "total_ingred_copy = []\n",
    "\n",
    "for i in range(len(copy['ingredients'])):\n",
    "    total_ingred_copy.extend(copy['ingredients'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d1d89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of list is 0\n",
      "\n",
      "Elements from the list containing the characters:\n",
      "Float64Index([], dtype='float64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danra\\AppData\\Local\\Temp/ipykernel_11472/3419566289.py:20: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  series_version = pd.Series(mylist)\n"
     ]
    }
   ],
   "source": [
    "## Example of the search function being used to check that the brand kraft was removed\n",
    "\n",
    "search(total_ingred_copy,'kraft',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2022c7",
   "metadata": {},
   "source": [
    "# Checking the results after removing all lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2745e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of unedited ingredients list is 6703\n",
      "length of reduced ingredients list is 5640\n"
     ]
    }
   ],
   "source": [
    "## Checking number of \"unique\" items left\n",
    "\n",
    "print(\"length of unedited ingredients list is\", len(pd.Series(total_ingredients).value_counts().index))\n",
    "print(\"length of reduced ingredients list is\", len(pd.Series(total_ingred_copy).value_counts().index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb743d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
