{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bb188c",
   "metadata": {},
   "source": [
    "In this notebook, we explore the decision tree model and tune the hyperparameters. We work with three different training sets, each with the a different subset of features. \n",
    "- train_0 contains all the original features (ingredients).\n",
    "- train_1 contains features which were found by scraping a website of all food-related words.\n",
    "- train_2 contains features which were found by picking ingredients which occured at least 50 times in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d136231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "#train_0 = pd.read_csv(\"../Data/original_data.csv\") # This line runs very slowly on my computer and using train_0 always leads to python kernel crashing\n",
    "train_1 = pd.read_csv(\"../Data/key_words_data.csv\")\n",
    "train_2 = pd.read_csv(\"../Data/train_trimmed.csv\")\n",
    "\n",
    "train_list = {1:train_1, 2:train_2} #Do one at a time in case the kernel crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccfe3d",
   "metadata": {},
   "source": [
    "## Tunig the depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make stratified k fold splits of the data\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=429)\n",
    "\n",
    "cv_accuracy_score = {i:[] for i in train_list} #To store the cross-validation accuracy score\n",
    "cv_recall_score = {i:[] for i in train_list}\n",
    "cv_f1_score = {i:[] for i in train_list}\n",
    "max_depth = {0:100,1:50,2:200} #To store the maximum depths for hyperparameter tuning\n",
    "\n",
    "## Use cross-validation to tune the depth of the decision tree\n",
    "for i,train in train_list.items(): \n",
    "    X_train = train.drop(columns=[\"id\",\"cuisine\"])\n",
    "    y_train = train[\"cuisine\"]\n",
    "        \n",
    "    for d in range(1,max_depth[i]+1):\n",
    "        clf = DecisionTreeClassifier(max_depth=d)\n",
    "        accuracy_list = [] #To store the accuracy for each of the 5 cross-validation pair. \n",
    "        f1_list = []\n",
    "        recall_list = []\n",
    "        for train_idx, test_idx in skf.split(X_train,y_train):\n",
    "            X_train_train, y_train_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            X_holdout, y_holdout = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "            clf.fit(X_train_train,y_train_train)\n",
    "            prediction = clf.predict(X_holdout)\n",
    "            accuracy_list.append(accuracy_score(y_holdout,prediction))\n",
    "            f1_list.append(f1_score(y_holdout,prediction,average=\"weighted\"))\n",
    "            recall_list.append(recall_score(y_holdout,prediction,average=\"weighted\"))\n",
    "            \n",
    "        cv_accuracy_score[i].append(np.mean(accuracy_list))\n",
    "        cv_f1_score[i].append(np.mean(f1_list))\n",
    "        cv_recall_score[i].append(np.mean(recall_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc703b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the KPI's for further analysis\n",
    "kpi_df = {}\n",
    "for i in train_list:\n",
    "    df = pd.DataFrame(\n",
    "        np.transpose([range(1,max_depth[i]+1), cv_accuracy_score[i], cv_f1_score[i]\n",
    "                       , cv_recall_score[i]]),\n",
    "                     columns=[\"depth\",\"cv accuracy\",\"cv f1 score\", \"cv recall score\"])\n",
    "    kpi_df[i] = df\n",
    "\n",
    "## Export KPI data as a csv\n",
    "for i in train_list: \n",
    "    filename = \"decision_tree_hyperparameter_tuning_train_\" + str(i) + \".csv\"\n",
    "    kpi_df[i].to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95583f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracy vs depth\n",
    "for i in train_list:\n",
    "    plt.figure()\n",
    "    plt.title(\"Cross-validation accuracy vs depth of descision tree for train data \"+str(i))\n",
    "    plt.xlabel(\"Depth of decision tree\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(range(1,max_depth[i]+1),cv_accuracy_score[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17024482",
   "metadata": {},
   "source": [
    "## Results after tuning the max_depth \n",
    "- train_1 - best max_depth is 35, accuracy = 59%\n",
    "- train_2 - max_depth ~114 gives about 58% accuracy and then the accuracy slowly increases uptil about max_depth 137 to 59% \n",
    "- train_0 - stops around max_depth 14 and then kernel crashes \n",
    "\n",
    "## Conclusion \n",
    "In the context of decision trees, the final models have max_depth 35 and 114 for the training sets train_1 and train_2 respectively. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
